{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#http://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='C:/Users/Lenovo/Desktop/iadap/3-2/IR/project/GOT-character-s-death-Prediction-master/'\n",
    "data1=pd.read_csv(path+'Formated data.csv')\n",
    "data=pd.read_csv(path+'Formated_data_corrected.csv')\n",
    "\n",
    "col_is_alive=pd.DataFrame(data1['isAlive'])\n",
    "data=col_is_alive.join(data)\n",
    "\n",
    "#data.info()\n",
    "x,y=list(),list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category(data):\n",
    "    data.title=data.title.astype('category')  \n",
    "    data.Culture=data.Culture.astype('category')        \n",
    "    data.name=data.name.astype('category')\n",
    "    data.house=data.house.astype('category')\n",
    "    \n",
    "    cat_columns = data.select_dtypes(['category']).columns\n",
    "    data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    \n",
    "    unique,counts=np.unique(data['title'],return_counts=True)\n",
    "    diction=dict(zip(unique,counts))\n",
    "    data['title']=data['title'].apply(lambda x: 1/diction[x]) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_x_y(data):\n",
    "    x=data.loc[:,'name':]\n",
    "    #print(x)\n",
    "    y=data.loc[:,'isAlive']  \n",
    "    #print(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1946,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=category(data)    \n",
    "x,y=create_x_y(data)  \n",
    "y=np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1946, 53)\n",
      "(1946, 20)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x_new = SelectKBest(chi2, k=20).fit_transform(x, y)\n",
    "print(x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.82700000e+03   1.00000000e+00   2.90000000e+01   1.97000000e+02\n",
      "   0.00000000e+00   0.00000000e+00   6.05351171e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(x_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.74981114e-01   5.86108623e-02   2.96831673e-02   8.41182713e-02\n",
      "   1.06811524e-01   3.05032830e-02   2.43799865e-02   3.10447104e-02\n",
      "   7.28468060e-02   4.09600973e-02   2.76897802e-02   3.08099390e-02\n",
      "   2.29245526e-01   1.73082395e-03   1.04271495e-03   1.08466097e-03\n",
      "   1.84475320e-04   9.07933328e-04   1.34011015e-03   1.23248349e-03\n",
      "   4.95384376e-04   5.68253157e-04   1.03029746e-03   1.45038067e-03\n",
      "   1.07175459e-03   3.53733377e-04   1.77048820e-03   9.80048105e-04\n",
      "   3.58991285e-04   3.75840896e-04   3.80056577e-04   2.61090930e-04\n",
      "   9.28816072e-04   1.77778711e-03   1.61354038e-03   0.00000000e+00\n",
      "   4.71204493e-04   1.29018186e-05   2.28060203e-03   2.43961753e-03\n",
      "   3.69042276e-04   7.08580452e-04   0.00000000e+00   3.66887211e-03\n",
      "   2.01741354e-03   2.55733697e-03   3.98758131e-04   7.50855832e-04\n",
      "   1.65301819e-03   4.52348450e-03   2.81084310e-03   6.53300598e-03\n",
      "   6.17973026e-03]\n"
     ]
    }
   ],
   "source": [
    "y_old=y\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(x, y)\n",
    "print(clf.feature_importances_ )\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "x_new = model.transform(x)\n",
    "x_new.shape\n",
    "\n",
    "y_new=np.zeros((len(y_old),2))\n",
    "for i in range(len(y_old)):\n",
    "    if y_old[i]==1:\n",
    "        y_new[i]=[1,0]\n",
    "        #print(y_new[i])\n",
    "    else:\n",
    "        y_new[i]=[0,1]\n",
    "        #print(y_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1556, 2)\n",
      "(1556, 13)\n"
     ]
    }
   ],
   "source": [
    "y=y_new.reshape((y_new.shape[0],2))\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_new,y,test_size=0.2)\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "tf.set_random_seed(random_state)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases, keep_prob):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 38\n",
    "n_input = x_train.shape[1]\n",
    "n_classes = 2\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 1000\n",
    "display_step = 100\n",
    "batch_size = 32\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = multilayer_perceptron(x, weights, biases, keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 1194.289983431\n",
      "Epoch: 0101 cost= 758.827219963\n",
      "Epoch: 0201 cost= 403.400506814\n",
      "Epoch: 0301 cost= 262.292869965\n",
      "Epoch: 0401 cost= 105.365829746\n",
      "Epoch: 0501 cost= 30.437450568\n",
      "Epoch: 0601 cost= 7.227172511\n",
      "Epoch: 0701 cost= 2.518039990\n",
      "Epoch: 0801 cost= 1.683328706\n",
      "Epoch: 0901 cost= 1.635202954\n",
      "Optimization Finished!\n",
      "Accuracy: 0.74359\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(len(x_train) / batch_size)\n",
    "        x_batches = np.array_split(x_train, total_batch)\n",
    "        y_batches = np.array_split(y_train, total_batch)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = x_batches[i], y_batches[i]\n",
    "            _, c = sess.run([optimizer, cost], \n",
    "                            feed_dict={\n",
    "                                x: batch_x, \n",
    "                                y: batch_y, \n",
    "                                keep_prob: 0.8\n",
    "                            })\n",
    "            avg_cost += c / total_batch\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
